{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T00:38:51.128390",
     "start_time": "2016-07-31T00:38:50.883218"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from StringIO import StringIO\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from csv_pkl_sql import save_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get airport location information from [fallingrain.com](http://www.fallingrain.com/world/index.html)\n",
    "\n",
    "Import cleaned location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:45:02.553468",
     "start_time": "2016-07-31T16:45:02.424917"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_key = pd.read_pickle('../pkl/00_cleaned_city_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-31T16:45:03.130417",
     "start_time": "2016-07-31T16:45:03.069017"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>location_type</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>province</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>province</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Ciudad de Buenos Aires</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location location_type    country                province  \\\n",
       "0  Argentina-Buenos_Aires      province  Argentina            Buenos Aires   \n",
       "1          Argentina-CABA      province  Argentina  Ciudad de Buenos Aires   \n",
       "\n",
       "  county  city  \n",
       "0   None  None  \n",
       "1   None  None  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_key.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:32:38.308980",
     "start_time": "2016-07-30T15:32:38.297790"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location            0\n",
       "location_type       0\n",
       "country             0\n",
       "province           46\n",
       "county           1451\n",
       "city              368\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_key.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:32:38.866610",
     "start_time": "2016-07-30T15:32:38.855278"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Argentina', 'Brazil', 'Colombia', 'Dominican Republic', 'Ecuador',\n",
       "       'El Salvador', 'Guatemala', 'Haiti', 'Mexico', 'Nicaragua',\n",
       "       'Panama', 'United States'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_countries = location_key.country.unique()\n",
    "data_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape a table of country abbreviations from fallingrain.com that will be used to build the URLs for country information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:05.884833",
     "start_time": "2016-07-30T15:32:40.171309"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = pd.read_html(requests.get('http://www.fallingrain.com/world/index.html').text)\n",
    "countries = pd.DataFrame({'full':tables[0].values.ravel()}).dropna()\n",
    "countries[['abbrev', 'name']] = (countries.full\n",
    "                                 .str.extract(r\"\"\"([A-Z]{2}) (.+)\"\"\", expand=True)\n",
    "                                 )\n",
    "\n",
    "mask = countries.name.isin(data_countries)\n",
    "countries = countries[mask].reset_index(drop=True)\n",
    "assert mask.sum() == len(data_countries)\n",
    "\n",
    "countries['url'] = countries.abbrev.apply(lambda x: 'http://www.fallingrain.com/world/{}/'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "United States state abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:06.526013",
     "start_time": "2016-07-30T15:33:05.887015"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_abbreviations = pd.read_csv(StringIO(requests.get('http://www.fonz.net/blog/wp-content/uploads/2008/04/states.csv').text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the airports\n",
    "\n",
    "### All countries except the United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:06.536677",
     "start_time": "2016-07-30T15:33:06.527986"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries['airports'] = countries.loc[countries.abbrev!='US','url'].apply(lambda x: x+'airports.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:23.438767",
     "start_time": "2016-07-30T15:33:06.540260"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for url in countries.airports:\n",
    "    if url is not np.NaN:\n",
    "        table = pd.read_html(url)[0]\n",
    "        table.columns = table.iloc[0]\n",
    "        table = table.iloc[1:]\n",
    "        \n",
    "        country_code = re.search(r\"\"\"world\\/([A-Z]{2})\\/\"\"\",url).group(1)\n",
    "        country_name = countries.loc[countries.abbrev==country_code, 'name'].values[0]\n",
    "        table['country'] = country_name\n",
    "        df_list.append(table)\n",
    "        \n",
    "        \n",
    "airports_df_1 = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just the United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:23.476914",
     "start_time": "2016-07-30T15:33:23.440848"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'states':location_key.loc[location_key.country=='United States','province'].unique()})\n",
    "states = pd.merge(states, state_abbreviations, left_on='states', right_on='State', how='left')\n",
    "\n",
    "states.loc[states.states=='Puerto Rico', 'Abbreviation'] = 'PR'\n",
    "states.loc[states.states=='American Samoa', 'Abbreviation'] = 'AS'\n",
    "states.loc[states.states=='Virgin Islands', 'Abbreviation'] = 'VI'\n",
    "states.drop(['State'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:33:23.488228",
     "start_time": "2016-07-30T15:33:23.480487"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states['airports'] = states.Abbreviation.apply(lambda x: 'http://www.fallingrain.com/world/US/{}/airports.html'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:34:04.516707",
     "start_time": "2016-07-30T15:33:23.492739"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for url in states.drop_duplicates(subset=['Abbreviation']).airports:\n",
    "    if url is not np.NaN:\n",
    "        table = pd.read_html(url)[0]\n",
    "        table.columns = table.iloc[0]\n",
    "        table = table.iloc[1:]\n",
    "        \n",
    "        state_code = re.search(r\"\"\"world\\/US\\/([A-Z]{2})\\/\"\"\",url).group(1)\n",
    "        state_name = states.loc[states.Abbreviation==state_code, 'states'].values[0]\n",
    "        table['state'] = state_name\n",
    "        table['country'] = 'United States'\n",
    "        df_list.append(table)\n",
    "        \n",
    "airports_df_2 = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine airport dataframes\n",
    "Combine and clean columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:34:04.739548",
     "start_time": "2016-07-30T15:34:04.519038"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>kind</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_runway</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BAHIA BLANCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BHI</td>\n",
       "      <td>SAZB</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-38.725</td>\n",
       "      <td>-62.169</td>\n",
       "      <td>8579.0</td>\n",
       "      <td>COMANDANTE ESPORA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SADM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-34.676</td>\n",
       "      <td>-58.643</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>MORON</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EPA</td>\n",
       "      <td>SADP</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-34.610</td>\n",
       "      <td>-58.613</td>\n",
       "      <td>6923.0</td>\n",
       "      <td>EL PALOMAR</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EZE</td>\n",
       "      <td>SAEZ</td>\n",
       "      <td>Large</td>\n",
       "      <td>-34.822</td>\n",
       "      <td>-58.536</td>\n",
       "      <td>10827.0</td>\n",
       "      <td>MINISTRO PISTARINI</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-34.559</td>\n",
       "      <td>-58.416</td>\n",
       "      <td>6890.0</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  FAA IATA  ICAO    kind  latitude  longitude  max_runway  \\\n",
       "56  BAHIA BLANCA  NaN  BHI  SAZB  Medium   -38.725    -62.169      8579.0   \n",
       "77  Buenos Aires  NaN  NaN  SADM  Medium   -34.676    -58.643      9350.0   \n",
       "78  Buenos Aires  NaN  EPA  SADP  Medium   -34.610    -58.613      6923.0   \n",
       "79  Buenos Aires  NaN  EZE  SAEZ   Large   -34.822    -58.536     10827.0   \n",
       "80  Buenos Aires  NaN  AEP  SABE  Medium   -34.559    -58.416      6890.0   \n",
       "\n",
       "                        name    country state  \n",
       "56         COMANDANTE ESPORA  Argentina   NaN  \n",
       "77                     MORON  Argentina   NaN  \n",
       "78                EL PALOMAR  Argentina   NaN  \n",
       "79        MINISTRO PISTARINI  Argentina   NaN  \n",
       "80  AEROPARQUE JORGE NEWBERY  Argentina   NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports = pd.concat([airports_df_1, airports_df_2], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Clean up column names\n",
    "name_mapper = dict([(x,x.lower().replace(' ','_')) \n",
    "               for x in ['Kind','City','Name','Latitude','Longitude','Max Runway']])\n",
    "\n",
    "airports = airports.rename(columns=name_mapper)\n",
    "\n",
    "# Column formatting\n",
    "airports['latitude'] = airports.latitude.str.replace(r\"\"\"\\([NS]\\)\"\"\", '').astype(float)\n",
    "airports['longitude'] = airports.longitude.str.replace(r\"\"\"\\([EW]\\)\"\"\", '').astype(float)\n",
    "airports['max_runway'] = airports.max_runway.str.replace(r\"\"\" ft\"\"\", '').astype(float)\n",
    "\n",
    "# Extract just the medium and large airports\n",
    "mask = airports.kind.isin(['Medium','Large'])\n",
    "airports = airports[mask]\n",
    "\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:34:04.749531",
     "start_time": "2016-07-30T15:34:04.741963"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Unused attempt at using airport name and location fuzzy string matching to determine latitude and longitude\n",
    "# Decided to use google search instead\n",
    "\n",
    "# airport_array = arg_air['name'].str.lower().str.replace(' airport','')\n",
    "# arg_loc['airport_index'] = -1\n",
    "\n",
    "# for row,dat in arg_loc.iterrows():\n",
    "#     location_text = dat[dat.location_type].lower()\n",
    "#     location_index = dat.name\n",
    "    \n",
    "#     match_value = process.extractOne(location_text, airport_array)[0]\n",
    "#     match_index = airport_array.loc[airport_array==match_value].index[0]\n",
    "    \n",
    "#     arg_loc.loc[location_index, 'airport_index'] = match_index\n",
    "#     print(location_text, match_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:34:56.236721",
     "start_time": "2016-07-30T15:34:56.227284"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2062"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-30T15:35:37.409918",
     "start_time": "2016-07-30T15:34:57.530441"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_it(airports, '02_airport_information_fallingrain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
